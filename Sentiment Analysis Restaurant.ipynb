{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import necessary packages\n",
        "#from string import punctuation\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.classify import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load Yelp review of midland brew house\n",
        "data = pd.read_csv('/content/sample_data/bonefish_grill.csv')"
      ],
      "metadata": {
        "id": "bdwZEmQqRMFL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WGz7EEvdMwhk"
      },
      "outputs": [],
      "source": [
        "#Recode the ratings. 1-3 = Negative, 4-5 = Positive.\n",
        "#Created sentiment to holds the value as negative if 3 or below and positive if there is a higher rating\n",
        "data['sentiment'] = data['rating'].apply(lambda x: 'Negative' if x <= 3 else 'Positive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#punkt enables the word_tokenize\n",
        "nltk.download('punkt')\n",
        "#stopwords enables stopwords to be removed\n",
        "nltk.download('stopwords')\n",
        "def clean_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    #isalnum removes punctuation\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "    #.lower converts words to lower case\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "#takes cleaned text and assigns it to cleaned_review column\n",
        "data['cleaned_review'] = data['review'].apply(clean_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAYiWjs6RyFL",
        "outputId": "a9af9d69-8462-4565-86d6-3bd2d0f5bd71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data 70/30\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_review'], data['sentiment'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Used to set up nltk by extracting words and making eache one it's own feature\n",
        "def extract_features(text):\n",
        "    words = text.split()\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "#sets up features and labels for training\n",
        "X_train_features = [(extract_features(text), label) for text, label in zip(X_train, y_train)]\n",
        "X_test_features = [(extract_features(text), label) for text, label in zip(X_test, y_test)]\n",
        "\n",
        "# Train Naïve Bayes classifier\n",
        "nb_classifier = nltk.NaiveBayesClassifier.train(X_train_features)"
      ],
      "metadata": {
        "id": "I2QupUfaT5Ro"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier.train(X_train_features)"
      ],
      "metadata": {
        "id": "SFaatfISNKQ-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression classifier\n",
        "lr_classifier = SklearnClassifier(LogisticRegression())\n",
        "lr_classifier.train(X_train_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szzVTaDYZqrS",
        "outputId": "07f81b9f-a6d5-4f43-c549-eacb31d64465"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SklearnClassifier(LogisticRegression())>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test classifiers\n",
        "y_pred_nb = [nb_classifier.classify(extract_features(text)) for text in X_test]\n",
        "y_pred_lr = [lr_classifier.classify(extract_features(text)) for text in X_test]\n",
        "y_pred_dt = [dt_classifier.classify(extract_features(text)) for text in X_test]\n",
        "\n",
        "# Print classification reports\n",
        "print(\"Naïve Bayes Classifier:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "print(\"\\nLogistic Regression Classifier:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"\\nDecision Tree Classifier:\")\n",
        "print(classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoQFFAv0l7qc",
        "outputId": "d4e069fc-4597-41c0-b78b-ed03226c551c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.47      0.92      0.62        37\n",
            "    Positive       0.93      0.51      0.66        78\n",
            "\n",
            "    accuracy                           0.64       115\n",
            "   macro avg       0.70      0.72      0.64       115\n",
            "weighted avg       0.78      0.64      0.65       115\n",
            "\n",
            "\n",
            "Logistic Regression Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.57      0.57      0.57        37\n",
            "    Positive       0.79      0.79      0.79        78\n",
            "\n",
            "    accuracy                           0.72       115\n",
            "   macro avg       0.68      0.68      0.68       115\n",
            "weighted avg       0.72      0.72      0.72       115\n",
            "\n",
            "\n",
            "Decision Tree Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.47      0.51      0.49        37\n",
            "    Positive       0.76      0.73      0.75        78\n",
            "\n",
            "    accuracy                           0.66       115\n",
            "   macro avg       0.62      0.62      0.62       115\n",
            "weighted avg       0.67      0.66      0.66       115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print accuracy\n",
        "print(\"\\nAccuracy:\")\n",
        "print(\"Naïve Bayes Classifier:\", nltk.classify.accuracy(nb_classifier, X_test_features))\n",
        "print(\"Logistic Regression Classifier:\", nltk.classify.accuracy(lr_classifier, X_test_features))\n",
        "print(\"Decision Tree Classifier:\", nltk.classify.accuracy(dt_classifier, X_test_features))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48eAW4KcNdAD",
        "outputId": "fbdbe7ec-e883-4282-c38d-8f15861ff466"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy:\n",
            "Naïve Bayes Classifier: 0.6434782608695652\n",
            "Logistic Regression Classifier: 0.7217391304347827\n",
            "Decision Tree Classifier: 0.6608695652173913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate AUC for each classifier\n",
        "auc_nb = roc_auc_score(y_test, [nb_classifier.prob_classify(extract_features(text)).prob('Positive') for text in X_test])\n",
        "auc_lr = roc_auc_score(y_test, [lr_classifier.prob_classify(extract_features(text)).prob('Positive') for text in X_test])\n",
        "\n",
        "\n",
        "# Print AUC for each classifier\n",
        "print(\"\\nAUC:\")\n",
        "print(\"Naïve Bayes Classifier:\", auc_nb)\n",
        "print(\"Logistic Regression Classifier:\", auc_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiFO2X4JOSoM",
        "outputId": "fa8ac0ab-6c06-4554-d6c5-a9fd44f1a452"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AUC:\n",
            "Naïve Bayes Classifier: 0.7321552321552321\n",
            "Logistic Regression Classifier: 0.7668052668052667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is directly from chatgpt as I didn't understand why I couldn't get auc score for decision tree\n",
        "# Get predicted labels for Decision Tree classifier\n",
        "y_pred_dt = [dt_classifier.classify(extract_features(text)) for text in X_test]\n",
        "\n",
        "# Convert predicted labels to binary values (0 or 1)\n",
        "y_pred_dt_binary = [1 if label == 'Positive' else 0 for label in y_pred_dt]\n",
        "\n",
        "# Convert actual labels to binary values (0 or 1)\n",
        "y_test_binary = [1 if label == 'Positive' else 0 for label in y_test]\n",
        "\n",
        "# Calculate AUC for Decision Tree classifier\n",
        "auc_dt = roc_auc_score(y_test_binary, y_pred_dt_binary)\n",
        "\n",
        "# Print AUC for Decision Tree classifier\n",
        "print(\"\\nAUC:\")\n",
        "print(\"Decision Tree Classifier:\", auc_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yC28zKqa14x",
        "outputId": "87655e6a-8d74-4fda-d70b-c67f780994b7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AUC:\n",
            "Decision Tree Classifier: 0.6221413721413721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In these reviews there is class imbalance. Our goal is to have the best model at predicting whether the review is negative or positive. Therefore the best metric for comparing models is F-1 score which takes into effect both the recall and precision to deal with class imbalance. In our case the weighted average F-1 scores are Naïve Bayes Classifier: 0.65\n",
        "Logistic Regression Classifier: 0.72\n",
        "Decision Tree Classifier: 0.66. Therefore Logisitic Regression Classifier is the best model.\n",
        "\n"
      ],
      "metadata": {
        "id": "aB3S-uLgMF29"
      }
    }
  ]
}