{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7AcfH84OVW3g"
      },
      "outputs": [],
      "source": [
        "#import necessary packages\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Read your CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('Arriba Mexican Grill.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxPULDkodVGc",
        "outputId": "c00d1fb5-bd3e-4e20-d6f7-714945c27930"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download NLTK resources for preprocessing\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define a tokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "# Define a function to clean and tokenize text\n",
        "def preprocess_text(text):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Clean and tokenize the review text\n",
        "df['tokenized_review'] = df['review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J24sNRibX8V2",
        "outputId": "ff01cac5-8fc0-417e-eb80-008f0d6467b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ask', 0.9771250486373901), ('always', 0.9764689207077026), ('meal', 0.9759775996208191), ('big', 0.975333034992218), ('arriba', 0.9752405881881714)]\n"
          ]
        }
      ],
      "source": [
        "# Build a Word2Vec model\n",
        "w2v_model = Word2Vec(df['tokenized_review'].tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Find word similarities to quesadilla\n",
        "print(w2v_model.wv.most_similar('quesadilla', topn=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr1M0yoIkmzc"
      },
      "source": [
        "Given the lack of context \"'ask','always', and 'arriba'\" don't have a clear connection. However \"big\" and \"meal\" are informative.  This tells me that despite being listed as an appetizer on the menu, the quesadilla is big and can serve as a meal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZMvxoEzj1nz",
        "outputId": "923feffe-3010-4421-e75b-dac849773d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('food', 0.9956725835800171), ('would', 0.9956137537956238), ('like', 0.9954841136932373), ('got', 0.9953912496566772), ('us', 0.9953407049179077)]\n"
          ]
        }
      ],
      "source": [
        "# Find word similarities to taco\n",
        "print(w2v_model.wv.most_similar('taco', topn=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azVjDplolY0G"
      },
      "source": [
        "Considering Taco is a food that makes sense. However, \"'would','like','got','us'\" don't have a clear connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdCr2h29j3Hd",
        "outputId": "fae8b3de-fcb2-475c-d3ad-9650b89ba21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('time', 0.9871467351913452), ('us', 0.9870790839195251), ('plate', 0.9870587587356567), ('make', 0.9868842363357544), ('take', 0.9868794083595276)]\n"
          ]
        }
      ],
      "source": [
        "# Find word similarities to burrito\n",
        "print(w2v_model.wv.most_similar('burrito', topn=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91KeJXOTlZxx"
      },
      "source": [
        "The only word that has a direct connection to burrito is plate as that is an official menu item. I'm curious in what context time is associated, whether that means burritos take a while or come quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mnzjouGScYDa"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "w2v_model.save('Arriba-w2v.bin')\n",
        "\n",
        "# Load the saved model\n",
        "saved_model = gensim.models.Word2Vec.load('Arriba-w2v.bin')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
